{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Self-Supervised Learning (SSL) Training with SpecAugment\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "from transformers import Wav2Vec2Model, Wav2Vec2Processor, BertTokenizer, BertForMaskedLM\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Audio Dataset with SpecAugment\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, data_dir, augment=True):\n",
    "        self.files = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith('.wav')]\n",
    "        self.processor = Wav2Vec2Processor.from_pretrained('facebook/wav2vec2-base')\n",
    "        self.augment = augment\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        audio, sr = librosa.load(self.files[idx], sr=16000)\n",
    "        if self.augment:\n",
    "            audio = self.apply_spec_augment(audio, sr)\n",
    "        input_values = self.processor(audio, return_tensors=\"pt\", sampling_rate=16000).input_values\n",
    "        return input_values.squeeze(0)\n",
    "    \n",
    "    def apply_spec_augment(self, audio, sr):\n",
    "        mel_spec = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=128)\n",
    "        mel_spec = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "        time_masking = T.TimeMasking(time_mask_param=80)\n",
    "        freq_masking = T.FrequencyMasking(freq_mask_param=30)\n",
    "        mel_spec = time_masking(torch.tensor(mel_spec))\n",
    "        mel_spec = freq_masking(mel_spec)\n",
    "        return librosa.feature.inverse.mel_to_audio(mel_spec.numpy(), sr=sr)\n",
    "\n",
    "# SSL Audio Training\n",
    "\n",
    "def train_ssl_audio():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = Wav2Vec2Model.from_pretrained('facebook/wav2vec2-base').to(device)\n",
    "    dataset = AudioDataset(\"data/processed\")\n",
    "    dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=3e-5, weight_decay=0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.9)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(10):\n",
    "        for batch in dataloader:\n",
    "            batch = batch.to(device)\n",
    "            outputs = model(batch, output_hidden_states=True).hidden_states[-1]\n",
    "            loss = (outputs ** 2).mean()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        scheduler.step()\n",
    "        print(f\"Epoch {epoch+1}: Loss = {loss.item()}\")\n",
    "    \n",
    "    torch.save(model.state_dict(), \"models/ssl_audio_model.pth\")\n",
    "    print(\"SSL Audio training completed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_ssl_audio()\n",
    "\n",
    "# Text Dataset for SSL\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, data_path):\n",
    "        self.data = pd.read_csv(data_path)[\"transcript\"].dropna().tolist()\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        inputs = self.tokenizer(self.data[idx], return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "        return inputs.input_ids.squeeze(0), inputs.attention_mask.squeeze(0)\n",
    "\n",
    "# SSL Text Training\n",
    "def train_ssl_text():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = BertForMaskedLM.from_pretrained('bert-base-uncased').to(device)\n",
    "    dataset = TextDataset(\"data/processed/transcripts.csv\")\n",
    "    dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=3e-5, weight_decay=0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.9)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(10):\n",
    "        for input_ids, attention_mask in dataloader:\n",
    "            input_ids, attention_mask = input_ids.to(device), attention_mask.to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=input_ids)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        scheduler.step()\n",
    "        print(f\"Epoch {epoch+1}: Loss = {loss.item()}\")\n",
    "    \n",
    "    torch.save(model.state_dict(), \"models/ssl_text_model.pth\")\n",
    "    print(\"SSL Text training completed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_ssl_text()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
